{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-04T20:49:42.613305Z","iopub.execute_input":"2022-04-04T20:49:42.613608Z","iopub.status.idle":"2022-04-04T20:49:42.629128Z","shell.execute_reply.started":"2022-04-04T20:49:42.613578Z","shell.execute_reply":"2022-04-04T20:49:42.628180Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"sales = pd.read_csv(\"../input/housesalesprediction/kc_house_data.csv\")\nsales.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T20:49:42.631314Z","iopub.execute_input":"2022-04-04T20:49:42.631604Z","iopub.status.idle":"2022-04-04T20:49:42.730634Z","shell.execute_reply.started":"2022-04-04T20:49:42.631568Z","shell.execute_reply":"2022-04-04T20:49:42.729761Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"x = sales.iloc[:,3:]\ny = sales.iloc[:,2:3]\n","metadata":{"execution":{"iopub.status.busy":"2022-04-04T20:49:42.732093Z","iopub.execute_input":"2022-04-04T20:49:42.732373Z","iopub.status.idle":"2022-04-04T20:49:42.740683Z","shell.execute_reply.started":"2022-04-04T20:49:42.732340Z","shell.execute_reply":"2022-04-04T20:49:42.738984Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"print(x.isnull().sum())\nprint(y.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-04-04T20:49:42.743034Z","iopub.execute_input":"2022-04-04T20:49:42.743864Z","iopub.status.idle":"2022-04-04T20:49:42.761642Z","shell.execute_reply.started":"2022-04-04T20:49:42.743723Z","shell.execute_reply":"2022-04-04T20:49:42.760736Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"from sklearn import linear_model\nregr = linear_model.LinearRegression()\nregr.fit(x,y)\nprint('Variance score: %.2f' % regr.score(x, y))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T20:49:42.763508Z","iopub.execute_input":"2022-04-04T20:49:42.764329Z","iopub.status.idle":"2022-04-04T20:49:42.799229Z","shell.execute_reply.started":"2022-04-04T20:49:42.764285Z","shell.execute_reply":"2022-04-04T20:49:42.798041Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"if we use multiple linear regression, our variance will be score : 0.70. Let's calculate as train and test.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.33)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T20:49:42.801296Z","iopub.execute_input":"2022-04-04T20:49:42.801851Z","iopub.status.idle":"2022-04-04T20:49:42.834336Z","shell.execute_reply.started":"2022-04-04T20:49:42.801784Z","shell.execute_reply":"2022-04-04T20:49:42.833156Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"from sklearn import linear_model\nregr = linear_model.LinearRegression()\nregr.fit(x_train,y_train)\ny_pred = regr.predict(x_test)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2022-04-04T20:49:42.911500Z","iopub.execute_input":"2022-04-04T20:49:42.912074Z","iopub.status.idle":"2022-04-04T20:49:42.959162Z","shell.execute_reply.started":"2022-04-04T20:49:42.912008Z","shell.execute_reply":"2022-04-04T20:49:42.957331Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nprint('Variance score: %.2f' % regr.score(x_test, y_test))\nprint(\"R^2 Score : %.2f\" % r2_score(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T20:49:42.964455Z","iopub.execute_input":"2022-04-04T20:49:42.967536Z","iopub.status.idle":"2022-04-04T20:49:43.023612Z","shell.execute_reply.started":"2022-04-04T20:49:42.967395Z","shell.execute_reply":"2022-04-04T20:49:43.021960Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"you can see varience and r2_score values is same, so they are same things.","metadata":{}},{"cell_type":"markdown","source":"Let's try polynomial regression","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\npoly = PolynomialFeatures(degree=2)\nx_train_poly = poly.fit_transform(x_train)\nx_test_poly = poly.fit_transform(x_test)\nx_train_poly","metadata":{"execution":{"iopub.status.busy":"2022-04-04T20:49:43.026239Z","iopub.execute_input":"2022-04-04T20:49:43.032385Z","iopub.status.idle":"2022-04-04T20:49:43.132458Z","shell.execute_reply.started":"2022-04-04T20:49:43.032281Z","shell.execute_reply":"2022-04-04T20:49:43.131523Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"regr1 = linear_model.LinearRegression()\nregr1.fit(x_train_poly,y_train)\ny_pred_poly=regr1.predict(x_test_poly)\ny_pred_poly","metadata":{"execution":{"iopub.status.busy":"2022-04-04T20:49:43.134224Z","iopub.execute_input":"2022-04-04T20:49:43.134759Z","iopub.status.idle":"2022-04-04T20:49:43.312007Z","shell.execute_reply.started":"2022-04-04T20:49:43.134704Z","shell.execute_reply":"2022-04-04T20:49:43.310783Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nprint('Variance score: %.2f' % regr1.score(x_test_poly, y_test))\nprint(\"R^2 Score : %.2f\" % r2_score(y_test,y_pred_poly))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T20:49:43.314881Z","iopub.execute_input":"2022-04-04T20:49:43.318139Z","iopub.status.idle":"2022-04-04T20:49:43.337038Z","shell.execute_reply.started":"2022-04-04T20:49:43.318055Z","shell.execute_reply":"2022-04-04T20:49:43.336085Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"for degree 2, polynomial regression 0.82. we can calculate right now with a loop.","metadata":{}},{"cell_type":"code","source":"for i in range(1,5):\n    poly = PolynomialFeatures(degree=i)\n    x_train_poly = poly.fit_transform(x_train)\n    x_test_poly = poly.fit_transform(x_test)\n    regr1 = linear_model.LinearRegression()\n    regr1.fit(x_train_poly,y_train)\n    y_pred_poly=regr1.predict(x_test_poly)\n    print(f\"for degree = {i}\")\n    print('Variance score: %.2f' % regr1.score(x_test_poly, y_test))\n    print(\"R^2 Score : %.2f\" % r2_score(y_test,y_pred_poly))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T20:49:43.338702Z","iopub.execute_input":"2022-04-04T20:49:43.339718Z","iopub.status.idle":"2022-04-04T20:52:19.211374Z","shell.execute_reply.started":"2022-04-04T20:49:43.339657Z","shell.execute_reply":"2022-04-04T20:52:19.201122Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"the best degree is 2.","metadata":{}}]}